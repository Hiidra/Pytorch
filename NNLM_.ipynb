{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA=torch.cuda.is_available()\n",
    "\n",
    "# 为了保证实验结果可以复现，把各种random seed固定为同一值\n",
    "random.seed(53113)\n",
    "np.random.seed(53113)\n",
    "torch.manual_seed(53113)\n",
    "\n",
    "if USE_CUDA:\n",
    "    torch.cuda.manual_seed(53113)\n",
    "    \n",
    "BATCH_SIZE=32 # 一个batch中有多少个句子\n",
    "EMBEDDING_SIZE=650 # 100\n",
    "HIDDEN_SIZE=100\n",
    "MAX_VOCAB_SIZE=50000\n",
    "NUM_EPOCHS=5\n",
    "GRAD_CLIP=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT=torchtext.data.Field(lower=True)\n",
    "train,val,test=torchtext.datasets.LanguageModelingDataset.splits(path=\"E:\\\\Dvlp\\\\NLPData\\\\text8\",\n",
    "                                                train=\"text8.train.txt\",\n",
    "                                                validation=\"text8.dev.txt\",\n",
    "                                                 test=\"text8.test.txt\",\n",
    "                                                 text_field=TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train,max_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50002 | <class 'torchtext.vocab.Vocab'>\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab),\"|\",type(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.vocab.Vocab"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter,val_iter,test_iter=torchtext.data.BPTTIterator.splits(\n",
    "            (train,val,test),batch_size=BATCH_SIZE,device=device,\n",
    "            bptt_len=50,repeat=False,shuffle=True)\n",
    "# 每个句子的长度是50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iter(train_iter)\n",
    "batch=next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(TEXT.vocab.itos[i] for i in batch.text[:,0].data.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(TEXT.vocab.itos[i] for i in batch.target[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 组:\n",
      "organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing\n",
      "///\n",
      "of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations\n",
      "第 1 组:\n",
      "interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded\n",
      "///\n",
      "of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded as\n",
      "第 2 组:\n",
      "as authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society\n",
      "///\n",
      "authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however\n",
      "第 3 组:\n",
      "however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow\n",
      "///\n",
      "ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin\n",
      "第 4 组:\n",
      "kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in\n",
      "///\n",
      "and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic\n"
     ]
    }
   ],
   "source": [
    "# 可以看出整个语料是被连续切开的，并且batch.target只是batch.text错后一位的词\n",
    "for i in range(5):\n",
    "    print(\"第\",i,\"组:\")\n",
    "    batch=next(it)\n",
    "    print(\" \".join(TEXT.vocab.itos[i] for i in batch.text[:,0].data.cpu()))\n",
    "    print(\"///\")\n",
    "    print(\" \".join(TEXT.vocab.itos[i] for i in batch.target[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,hidden_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.embed=nn.Embedding(vocab_size,embed_size)\n",
    "        # self.lstm=nn.LSTM(embed_size,hidden_size,batch_first=True)\n",
    "        self.lstm=nn.LSTM(embed_size,hidden_size)\n",
    "        self.linear=nn.Linear(hidden_size,vocab_size)\n",
    "        self.hidden_size=hidden_size\n",
    "    def forward(self,text,hidden):\n",
    "        # text:[seq_length,batch_size]\n",
    "        emb=self.embed(text)\n",
    "        # emb:[seq_length,batch_size,embed_size]\n",
    "        output,hidden=self.lstm(emb,hidden)\n",
    "        # output:[seq_len,directions*batch_size,hidden_size],\n",
    "        # hidden:[1,batch_size,hidden_size]\n",
    "        \n",
    "        # 将output的前两个维度拼在一起，线性变换只能变换两维的\n",
    "        # 即：[(seq_len*batch_size),hidden_size]\n",
    "        out_vocab=self.linear(output.view(-1,output.shape[2]))\n",
    "        # out_vocab:[(seq_len*batch_size),vocab_size]\n",
    "        out_vocab=out_vocab.view(output.size(0),output.size(1),out_vocab.size(-1))\n",
    "        return out_vocab,hidden \n",
    "    def init_hidden(self,bsz,requires_grad=True):\n",
    "        # self.parameters()是一个iterator,可以用next()\n",
    "        weight=next(self.parameters())\n",
    "        # 创建和weight类型一样的全0tensor,一个h0，一个c0\n",
    "        return (weight.new_zeros((1,bsz,self.hidden_size),requires_grad=requires_grad),\n",
    "                weight.new_zeros((1,bsz,self.hidden_size),requires_grad=requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RNN(vocab_size=len(TEXT.vocab),\n",
    "          embed_size=EMBEDDING_SIZE,\n",
    "          hidden_size=HIDDEN_SIZE)\n",
    "if USE_CUDA:\n",
    "    model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(50002, 650)\n",
       "  (lstm): LSTM(650, 100)\n",
       "  (linear): Linear(in_features=100, out_features=50002, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4862, -0.1841,  1.3934,  ...,  0.2260,  0.2548,  0.7861],\n",
       "        [-0.1809,  0.2096, -0.6301,  ...,  1.3684, -0.0779, -0.6317],\n",
       "        [-2.0087,  3.0926, -1.4976,  ...,  0.6606,  0.3425,  1.6121],\n",
       "        ...,\n",
       "        [ 0.7753, -1.0300, -1.3122,  ...,  0.6954,  1.1550, -1.9044],\n",
       "        [-1.2658, -0.9943,  0.9980,  ..., -0.9651,  0.5646,  0.0829],\n",
       "        [-0.4681, -1.6434, -1.0714,  ...,  0.1356, -0.7706,  1.2884]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    # Wraps hidden states in new Tensors, to detach them from their history\n",
    "    if isinstance(h,torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "learning_rate=1e-3\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.825766563415527\n",
      "loss 7.169068813323975\n",
      "loss 6.89164924621582\n",
      "loss 6.93277645111084\n",
      "loss 6.8612060546875\n",
      "loss 6.728265762329102\n",
      "loss 6.498837471008301\n",
      "loss 6.479005813598633\n",
      "loss 6.628740310668945\n",
      "loss 6.466805458068848\n",
      "loss 6.257306098937988\n",
      "loss 6.663792133331299\n",
      "loss 6.258430004119873\n",
      "loss 6.445359706878662\n",
      "loss 6.482875823974609\n",
      "loss 6.056692123413086\n",
      "loss 6.2551045417785645\n",
      "loss 6.1858978271484375\n",
      "loss 6.357419013977051\n",
      "loss 6.122409820556641\n",
      "loss 6.310276985168457\n",
      "loss 6.306948661804199\n",
      "loss 6.042327404022217\n",
      "loss 5.848077774047852\n",
      "loss 6.184263229370117\n",
      "loss 6.026011943817139\n",
      "loss 6.008089542388916\n",
      "loss 6.361509799957275\n",
      "loss 6.161179065704346\n",
      "loss 6.125494003295898\n",
      "loss 6.147653102874756\n",
      "loss 6.271442890167236\n",
      "loss 6.118351459503174\n",
      "loss 6.0424981117248535\n",
      "loss 5.8611626625061035\n",
      "loss 5.901005268096924\n",
      "loss 6.0171332359313965\n",
      "loss 6.3321452140808105\n",
      "loss 6.029512882232666\n",
      "loss 5.9797844886779785\n",
      "loss 5.8587965965271\n",
      "loss 6.010201930999756\n",
      "loss 5.68246603012085\n",
      "loss 6.176576137542725\n",
      "loss 5.778144359588623\n",
      "loss 5.703250885009766\n",
      "loss 5.853229999542236\n",
      "loss 6.211365222930908\n",
      "loss 6.103480815887451\n",
      "loss 5.802047252655029\n",
      "loss 6.214573383331299\n",
      "loss 5.7576823234558105\n",
      "loss 6.018704414367676\n",
      "loss 5.557844161987305\n",
      "loss 6.00967264175415\n",
      "loss 5.7846198081970215\n",
      "loss 5.562497138977051\n",
      "loss 5.662352085113525\n",
      "loss 6.027616024017334\n",
      "loss 5.95888614654541\n",
      "loss 5.914818286895752\n",
      "loss 5.976272106170654\n",
      "loss 5.981800079345703\n",
      "loss 6.096348285675049\n",
      "loss 6.123992443084717\n",
      "loss 5.642772197723389\n",
      "loss 6.011587619781494\n",
      "loss 6.001087665557861\n",
      "loss 5.624086380004883\n",
      "loss 5.5450334548950195\n",
      "loss 5.799130916595459\n",
      "loss 5.789076328277588\n",
      "loss 5.607882022857666\n",
      "loss 5.843568325042725\n",
      "loss 5.818995952606201\n",
      "loss 5.595156669616699\n",
      "loss 5.977591514587402\n",
      "loss 5.7472147941589355\n",
      "loss 5.5064778327941895\n",
      "loss 5.635199546813965\n",
      "loss 5.683454513549805\n",
      "loss 5.470782279968262\n",
      "loss 5.894492149353027\n",
      "loss 5.549116611480713\n",
      "loss 5.754088878631592\n",
      "loss 5.641583442687988\n",
      "loss 5.6506171226501465\n",
      "loss 5.628276348114014\n",
      "loss 5.862165927886963\n",
      "loss 5.878627300262451\n",
      "loss 5.706624984741211\n",
      "loss 5.711285591125488\n",
      "loss 5.563411712646484\n",
      "loss 5.749497890472412\n",
      "loss 5.800476551055908\n",
      "loss 5.491642475128174\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 305.25 MiB (GPU 0; 4.00 GiB total capacity; 2.30 GiB already allocated; 294.51 MiB free; 450.39 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0d1143d81983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mGRAD_CLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dvlp\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Dvlp\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 305.25 MiB (GPU 0; 4.00 GiB total capacity; 2.30 GiB already allocated; 294.51 MiB free; 450.39 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    it=iter(train_iter)\n",
    "    hidden=model.init_hidden(BATCH_SIZE)\n",
    "    for i,batch in enumerate(it):\n",
    "        data,target=batch.text,batch.target\n",
    "        # batch之间是相邻的，上一个batch最后的hidden，下一个batch还能用，内存可能会爆掉\n",
    "        hidden=repackage_hidden(hidden)\n",
    "        output,hidden=model(data,hidden) \n",
    "        # target:[seq_len,batch_size]\n",
    "        loss=loss_fn(output.view(-1,VOCAB_SIZE),target.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "        if i%100==0:\n",
    "            print(\"loss\",loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
